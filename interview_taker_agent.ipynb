{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHAh/FLBK3rmoUyfGB+EXt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RautRitesh/langgraph/blob/main/interview_taker_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DQwE_hH1v0SA"
      },
      "outputs": [],
      "source": [
        "parsed_data_resume={'full_name': 'Ritesh Raut',\n",
        "                    'summary': 'I am a dedicated and passionate undergraduate Computer Science student with extensive research experience in Deep Learning, Natural Language Processing (NLP), RAG architectures, autonomous AI agents, and production-grade system development.',\n",
        "                    'email': 'ritesh222@gmail.com',\n",
        "                    'phone': '+977-12345678',\n",
        "                    'skills': ['Python', 'C++', 'Julia', 'JavaScript', 'Dart', 'C#', 'TensorFlow', 'Scikit-learn', 'Pandas', 'NumPy', 'FAISS', 'LangChain', 'Hugging Face Transformers', 'RAG Architectures', 'SpaCy', 'NLTK', 'Git', 'GitHub', 'FastAPI', 'Django', 'Linux/Unix environments', 'Deep Learning', 'Computer Vision', 'Transfer Learning', 'System Scalability', 'Strategic Problem Solving', 'Cross-Functional Collaboration', 'User-Centric Design', 'Technical Communication'],\n",
        "                    'work_experience': [\n",
        "                        {'role': 'AI/ML Intern',\n",
        "                         'company': 'Huncha Digital',\n",
        "                         'duration': 'August 2025 – November 2025',\n",
        "                         'technologies': ['LangGraph', 'React', 'NLP', 'Speech Recognition', 'Machine Learning'],\n",
        "                         'key_achievements': ['Engineered a scalable LangGraph React Agent, implementing robust backend logic to autonomously resolve 100+ daily user queries with 93% accuracy, significantly reducing manual support load.', 'Developed a voice-based food ordering system leveraging NLP and speech recognition, increasing order processing efficiency by 30%.', 'Implemented multi-modal AI architectures integrating text, voice, and retrieval intelligence to optimize user interaction flows.', 'Collaborated with cross-functional teams to design and integrate multi-modal AI systems, aligning technical implementations with business requirements for text and voice intelligence.']},\n",
        "                         {'role': 'Academic Researcher',\n",
        "                          'company': 'Tribhuvan University',\n",
        "                          'duration': 'Spring 2024 – Present',\n",
        "                          'technologies': ['Machine Learning', 'Regression', 'Clustering', 'Power BI'],\n",
        "                          'key_achievements': ['Executed predictive modeling using Machine Learning algorithms (Regression & Clustering) on demographic data from 10 administrative wards to forecast service bottlenecks and optimize digital service delivery.',\n",
        "                                               'Applied analytical skills to audit Nepal’s National Identity (NNID) biometric architectures and cybersecurity protocols, proposing enhanced data protection mechanisms to mitigate identity fraud.', 'Engineered dynamic Power BI dashboards to visualize citizen interaction patterns for a population of 70,000+, achieving a 20% increase in municipal work efficiency through data-driven resource allocation.']}\n",
        "                        ],\n",
        "                    'projects': [\n",
        "                        {'name': 'Cogni-chat: RAG-Based Document Analysis System', 'description': 'Engineered a web-based Retrieval-Augmented Generation (RAG) application enabling conversational interaction with PDF, DOCX, and TXT files.',\n",
        "                         'technologies': ['RAG', 'Hugging Face', 'FAISS'], 'url': 'Hugging Face Space'},\n",
        "                         {'name': 'AI-Powered Skincare Diagnostic System', 'description': 'Developed and trained a custom Convolutional Neural Network (CNN) on diverse datasets, achieving a validation accuracy of 82% for skin type classification.',\n",
        "                          'technologies': ['Convolutional Neural Network', 'FastAPI'], 'url': None},\n",
        "                           {'name': 'Community Interest Calculator', 'description': 'Architected and deployed a localized mobile application using Flutter, automating complex interest calculations for community finance groups.',\n",
        "                            'technologies': ['Flutter'], 'url': None}\n",
        "                        ],\n",
        "                    'education': [{'degree': 'Bachelor of Science in Computer Science and Information Technology', 'institution': 'Tribhuvan University', 'year': 'Ongoing'}], 'certifications': []}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description=\"\"\"Focus: Neural Networks, LLM Agents (LangChain & LangGraph)\n",
        "Type: Internship (Full-time / Part-time / Remote / On-site – customize)\n",
        "Duration: 3–6 Months\n",
        "Location: Nepal / Remote\n",
        "\n",
        "About the Role\n",
        "\n",
        "We are looking for a hands-on AI/ML Intern who enjoys building things—not just reading papers. You will work on real-world AI systems, including neural network models and LLM-based agents using LangChain and LangGraph.\n",
        "\n",
        "This is a build-first internship. If you like experimenting, breaking things, fixing them, and shipping working AI features—this role is for you.\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "I6tClA5nwAgT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain-groq langchain-community langchain-core langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJttojlMxT8n",
        "outputId": "4ad9783b-fbbc-47f0-8e91-3cd92d3408ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_groq-1.1.2-py3-none-any.whl (19 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, groq, dataclasses-json, langchain-text-splitters, langchain-groq, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 groq-0.37.1 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-groq-1.1.2 langchain-text-splitters-1.1.0 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "from langchain_groq import ChatGroq\n",
        "from langgraph.graph import MessagesState, StateGraph, START, END\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "6DLjDnI9ysRD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WorkExperience(TypedDict):\n",
        "  role:str\n",
        "  company:str\n",
        "  technologies:list[str]\n",
        "  key_achievements:list[str]\n",
        "\n",
        "class Projects(TypedDict):\n",
        "  name:str\n",
        "  description:str\n",
        "  technologies:list[str]"
      ],
      "metadata": {
        "id": "zFCoHywm3ddM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(MessagesState):\n",
        "  workexperience:list[WorkExperience]\n",
        "  projects:list[Projects]\n",
        "  full_name:str\n",
        "  job_description:str"
      ],
      "metadata": {
        "id": "o6vspeBD394B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key=userdata.get('groq_api_key')"
      ],
      "metadata": {
        "id": "fI3lVhWD4nxa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGroq(model=\"openai/gpt-oss-120b\",api_key=api_key)"
      ],
      "metadata": {
        "id": "7tygnaZ-4zF1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt=\"\"\"You are hr agent whose main task is to ask question to the individual, you have got access to the user 'full_name' and the 'projects' , 'workexperience', 'job_description'.\n",
        "Your task is to generate the best question never say any answer, and also you have access to the previous answers of the user and question, you can also ask followup question if the answer is weak.\"\"\"\n",
        "prompt=ChatPromptTemplate.from_messages([\n",
        "    (\"system\",system_prompt),\n",
        "    MessagesPlaceholder(variable_name:\"chat_history\"),\n",
        "    (\"user\",\"The  full_name of user is {full_name},{projects},{workexperience},{job_description}\")\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "ImWMGjsN5z52"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_node(state:AgentState):"
      ],
      "metadata": {
        "id": "0-EKMsQS5so1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}